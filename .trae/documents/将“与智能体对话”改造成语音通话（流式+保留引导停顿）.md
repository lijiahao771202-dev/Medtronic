## 目标与效果
- 页面风格：仿电话界面（头像/标题/连接中…/挂断按钮），仅语音，不显示文字聊天框。
- 交互：按住或开启麦克风持续说话；智能体流式回应并立即播放；提供暂停/继续与挂断；显示对方声音波形。
- 保留“引导停顿/语速调整”：脚本中保留 [pause:..] / [rate:..] 指令，播放端继续按指令分段与停顿。

## 架构与数据流
- 前端（语音通话页）：
  - 采集麦克风：`getUserMedia({audio:true})`，用 `AnalyserNode` 绘制本地波形（来电侧）。
  - 语音转文字（STT）：优先用浏览器 Web Speech API（`webkitSpeechRecognition`）做流式识别；不支持时提供“按住说话”按钮，松开后批量发送文本。
  - LLM 流式生成：`openai.chat.completions.create({stream:true})`，接收 token 流。
  - 分段与引导：对累计文本做增量分段（沿用现有 `segmentsFromText`），遇到标点/指令形成短语或停顿；短语立即发送到本地 TTS 服务并排程播放；停顿合并到时间线。
  - 播放与波形：使用现有 `guidedTTS`，传入 `AnalyserNode` 显示对方音频的蓝色波形；支持 `pauseSpeaking/resumeSpeaking/stopSpeaking`。
- 后端（已存在）：
  - 继续使用 `server/app.py` 的 edge-tts WebSocket，将每个短语转为音频并流式回前端；短语级别即可满足“流式”体验（不用等待整段）。

## UI 改造
- 新增语音通话页 `VoiceCall.jsx`：
  - 顶部：头像+标题（如“心愈”或当前类型名）。
  - 中间：对方波形（蓝色柱/折线）与状态文案（连接中、正在回应…）。
  - 底部：
    - 主按钮：挂断（红色）
    - 次按钮：暂停/继续（保留引导停顿逻辑，暂停的是播放时间线）
    - 可选：麦克风开/关（指示采集状态）
- 在 `Agent.jsx` 将“与智能体对话”入口替换为“开始语音通话”按钮，导航到 `/agent/voice`。

## 关键实现细节
- 流式分段算法：
  - 维护 `pendingTextBuffer`；LLM token 到达时追加。
  - 使用正则在缓冲区内寻找可切分的边界：标点（，。！？；）、换行、或显式 `[pause:..]` 指令；每次切出“短语”立刻发 TTS；剩余内容保留继续等待。
  - 对 `[rate:..]` 变更后续短语速率（沿用现有逻辑）。
- 去重与同步：
  - 使用已实现的 `currentPlayToken` 防止旧会话残留声音。
  - 首段音频就绪时触发 `onReady`：隐藏“连接中”提示并开始绘制波形。
- 错误与兼容：
  - STT 不可用：显示提示与“按住说话”按钮（手动分段发送）。
  - 麦克风权限：引导用户授权；拒绝则降级为文本输入。

## 改动清单
1) 新建 `src/pages/VoiceCall.jsx`（电话界面与逻辑）
2) 在 `src/App.jsx` 添加路由 `/agent/voice`
3) 在 `src/pages/Agent.jsx` 改入口为“开始语音通话”
4) 新增 `src/utils/streamSegmentation.js`：提供增量分段 API（复用/调用 `segmentsFromText`，做缓冲增量切割）
5) 扩展 `guidedTTS.speakGuided` 使用 `onReady` 与 `analyser`（已具备）
6) 样式：补充电话界面样式和按钮状态

## 验收与测试
- 进入 `/agent/voice`：显示电话界面，“连接中…”
- 开启麦克风说话：识别的文本流式送入 LLM，短语边界即开始播放；对方波形出现并跳动。
- 暂停/继续正常工作；挂断清理音源/定时器/识别器。
- 包含 `[pause:..]`/`[rate:..]` 的流式文本能正确停顿与变速。

## 后续增强（可选）
- 将 STT 替换为更稳健的云服务（如 Azure/Whisper streaming）
- 在通话页加“态度提示轮播”作为对话背景提示文案
- 波形切换为频谱/时间域的可选样式